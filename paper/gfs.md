# gfs

# 0、摘要

​	Google 文件系统（GFS）是一种由 Google 设计和实现的文件系统。它是一种可扩展的分布式文件系统，专为大型分布式数据密集型应用程序而设计。其提供容错功能，即使出现硬件故障或其他问题，可以正常运行。设计时考虑运行在廉价机器上，因此比其他类型的文件系统成本更低。GFS可以同时处理大量数据和请求。虽然 Google 文件系统的许多目标与以前的分布式文件系统相同，但其设计是由对 Google 应用程序负载和技术环境的需要推动的。GFS的设计与早期文件系统假设背道而驰，这促使人们对截然不同的设计要点进行了探索。GFS成功满足谷歌的存储需求，并在公司内部广泛部署，用于生成和处理其服务所使用的数据存储平台。GFS中最大的集群有一千多台计算机上、数千个磁盘上，提供数百 TB 的存储空间，并且可以由数百个客户端同时访问。本文介绍了旨在支持分布式应用程序的文件系统接口扩展，讨论了谷歌文件系统设计的许多方面，并报告了微基准测试和实际使用的测量结果。



# 1、介绍

​	Google 文件系统 (GFS) 的设计和实施旨在满足谷歌不断增长的数据处理需求。GFS 与以前的分布式文件系统有着相似的目标，例如性能、可扩展性、可靠性和可用性。但是，GFS的设计是由对Google应用负载和技术环境的需求推动的，做出了部分与早期文件系统设计假设不同的地方。

​	**常态化的组件故障**：组件故障在 GFS 中很常见，因为文件系统由数百甚至数千台存储计算机组成，这些存储计算机由廉价的商品部件构建，并且可供相当数量的客户端计算机访问。组件的数量和质量决定了某些组件在任何给定时间都无法正常工作，有些组件无法从当前的故障中恢复过来。已观察到由应用程序错误、操作系统错误、人为错误以及磁盘、内存、连接器、网络和电源故障引起的问题。通过**持续监控**、**错误检测**、**容错**和**自动恢复**以保障系统可靠性和可用性。

​	**适配大文件**：GFS 处理大小为多 GB 的大文件，与处理较小文件的传统文件系统不同。在处理包含数十亿个对象、 TB级 快速增长的数据集时，传统文件系统需要管理数十亿个大约 KB 大小的文件，显得很笨拙。由于文件很大，必须重新设计文件系统的，例如 I/O 操作和块大小，以优化性能。

​	**尾部追加**：GFS 中的大多数文件都是通过追加数据写入的，不存在随机修改。一旦写入，文件只能被读取，而且通常只能按顺序读取。鉴于这种对大文件的访问模式，追加成为性能优化和原子性保证的重点，而在客户端中缓存数据块则失去了吸引力。
​	**统一设计应用程序和文件系统 API** 以提高灵活性，从而使整个系统受益。例如，GFS 放宽一致性模型，以简化文件系统。还引入了原子追加操作，这样多个客户端就可以同时追加到一个文件中，而无需进行额外的同步。本文稍后将详细讨论这些设计选择。
目前部署了GFS集群中，最大的拥有超过 1000 个存储节点，超过 300 TB 的磁盘存储，并且由不同计算机上的数百个客户端连续大量访问。



# 2、设计概览

​	GFS适用于大型分布式数据密集型应用程序。 该设计由对需求驱动，与之前的文件系统不同。 该系统在廉价的商用硬件上运行时提供容错能力，并为大量客户机提供高聚合性能。 



## 2.1、假设

-   GFS 由容易出现故障的**廉价商用机**构建。因此，系统必须持续监控自身，并定期检测、容忍组件故障，并迅速从组件故障中恢复。
-   GFS 旨在存储**少量的大文件**，预计有几百万个文件，每个文件的大小通常为 100 MB 或更大。多 GB 文件是常见情况，应加以有效管理。但是，必须支持小文件，但系统无需针对它们进行优化。
-   工作负载主要由两种读取组成：**大型流式读取**和**小型随机读取**。在大型流式读取中，单个操作通常读取数百 KB，更常见的是 1 MB 或更多。来自同一个客户端的连续操作通常会读取文件的连续区域。一个小的随机读取通常在某个任意偏移量下读取几KB。注重性能的应用程序通常会对其小读取进行批处理和排序，以稳定地浏览文件，而不是来回移动。
-   工作负载还有许多**大规模的顺序写入**，这些写入操作会将数据附加到文件中。写操作大小与读操作大小相似。写入文件后，很少会再次修改文件。支持在文件中任意位置进行小写入操作，但不一定要高效。
-   GFS 需要同时处理多个客户端向一个文件追加的请求。这些文件通常用作生产者-消费者队列或用于多向合并。数百个生产者（每台计算机运行一个）将同时追加到一个文件中。 最小的同步开销意味着系统应尽可能少地使用同步来实现原子性，因为同步可能是分布式系统的性能瓶颈。系统还必须确保稍后可以读取该文件，可以由其他客户端读取 。
-   GFS 针对于数据密集型应用，需要处理大量数据，高带宽比低延迟更重要。系统需要能够快速高效地处理大量数据，而不是专注于最大限度地减少传输单个数据所花费的时间。 这与传统文件系统的假设背道而驰，后者优先考虑低延迟而不是高带宽。 通过优先考虑高带宽，GFS能够满足其目标应用程序的需求，并为大量客户提供高综合性能。



## 2.2、接口

​	GFS 提供了用户熟悉的文件系统接口，但是没有实现诸如POSIX之类的标准API，这是一组操作系统标准。GFS 中的文件按目录层次结构组织，并由路径名标识，这是在文件系统中组织文件的常用方法。GFS 支持创建、删除、打开、关闭、读取和写入文件的常规操作，这些是文件系统的基本文件操作。
​	GFS 还具有快照和记录追加操作，这是传统文件系统中都没有的独特功能。Snapshot 以低成本创建文件或目录树的副本，这对于在不影响原始文件的情况下创建备份或测试更改非常有用。Record append 允许多个客户端同时向同一个文件追加数据，同时保证每个客户端追加的原子性。这对于实现多路合并结果和生产者-消费者队列很有用，许多客户端可以同时追加到这些队列而无需加锁。这些类型的文件对于构建大型分布式应用程序非常有用，这是 GFS 的主要用途。快照和记录附录分别在第 3.4 节和第 3.3 节中进行了进一步讨论，这两节提供了有关这些功能的更多详细信息。



## 2.3、架构

​	GFS由单个主服务器和多个区块服务器组成，可被多个客户端访问。只要计算机资源允许，可在同一台计算机上同时运行区块服务器和客户端，并且接收较低的可靠性。
​	GFS 中的文件分为固定大小的块，每个区块由创建区块时主服务器分配的不可变且全局唯一的 64 位区块句柄标识。Chunkservers 将区块作为 Linux 文件存储在本地磁盘上，并读取或写入由区块句柄和字节范围指定的区块数据。为了提高可靠性，每个区块都在多个区块服务器上备份。默认情况下，GFS 存储三个副本，但用户可以为文件命名空间的不同区域指定不同的复制级别。在多个区块服务器上复制区块可确保在出现硬件故障或其他问题时数据不会丢失。使用固定大小的区块可实现高效的数据处理，并减少网络延迟对性能的影响。

​	Master 负责维护所有文件系统**元数据**，包括各种类型的信息，例如命名空间（目录树）、访问控制信息、从文件到块的映射以及块的当前位置。Master 还控制系统范围内的活动，例如**块租约管理**，其中包括将租约分配给 chunkserver，以确保它们在一定时期内对特定区块具有独占访问权限，有助于防止冲突并确保数据一致性。孤立块的**垃圾收集**是 Master 执行的另一项重要任务，它涉及识别和删除不再需要或已损坏的块。Master 也负责管理块服务器之间的**块迁移**，包括将块从一台服务器移动到另一台服务器以平衡负载并确保最佳性能。Master 与每个块服务器维持**心跳**，以发送执行并收集状态信息。这使主机能够监控系统的运行状况并根据需要进行调整，以确保其继续平稳运行。

​	GFS 客户端代码链接到每个应用程序，该应用程序实现文件系统 API，并与 Master 和 Chunkservers 通信，代表应用程序读取或写入数据。 Client 与 Master 间交互元数据变更，但真实数据都直接发送到 ChunkServers。 GFS 不提供 POSIX API，因此不需要挂接 Linux vnode 层。

​	客户端和块服务器都不会缓存文件数据。客户端缓存几乎没有什么好处，因为大多数应用程序都会流式传输大文件或工作集太大而无法缓存。 没有客户端缓存可以消除缓存一致性问题，从而简化客户端和整个系统。但客户端会缓存元数据。 ChunkServers 不需要缓存文件数据，因为块存储为本地文件，而且 Linux 的缓冲区缓存已经将经常访问的数据保存在内存中。

​	

## 2.4、单主架构

​	GFS 只有一个 Master，它简化了设计，使 Master 能够利用全局信息做出复杂的块放置和块复制决策。 单主架构可以更好地协调和管理分布式文件系统。 Master 负责维护文件命名空间并跟踪每个数据块的位置。还负责将区块分配给区块服务器，并确保每个区块都有足够的副本以实现容错。 但是，必须尽量减少主节点参与读取和写入的情况，以防止其成为瓶颈。 客户端从不通过主节点读取和写入文件数据，以避免请求过载。 取而代之的是，客户端会询问主节点他们应该联系哪些区块服务器来读取或写入数据。 客户端会限时缓存元数据，并直接与块服务器交互。 此架构允许高效、可扩展的数据访问，同时仍能保持容错和一致性。

![image-20230812230839569](./images/gfs/image-20230812230839569.png)

​	通过图1来介绍简单的读流程。第一步是让客户端通过固定的块大小将应用指定的文件名和字节偏移量转换为文件内的块索引。 确定区块索引后，客户端会向 Master 发送包含文件名和块索引的请求。 然后，Master 用将块句柄和副本的位置返回客户端。 客户端使用文件名和块索引作为密钥缓存此信息，避免再与 Master 进行不必要的交互。缓存信息后，客户端向其中一个副本（通常是最接近的副本）发送请求，指定块句柄和该区块内的字节范围。 如果客户端需要再次读取相同的区块，在缓存的信息过期或文件重新打开前无需与 Master 交互。 实际上，客户端可以在同一个请求中请求多个块，而 Master 也同时返回多个块索引，这有助于减少后续客户端与 Master 的交互，而无额外开销。